# -*- coding: utf-8 -*-
"""Datathon

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rvGbC7lrSna7NFlVMXYa_Vb5x1ECImnb
"""

import json
import pandas as pd
import numpy as np
import pickle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

# =======================
# 1. Carregar os dados
# =======================


def load_json_to_df(path, orient='index'):
    with open(path, 'r', encoding='utf-8') as f:
        return pd.DataFrame.from_dict(json.load(f), orient=orient)


# Carregamento dos arquivos
jobs_df = load_json_to_df('bases/vagas.json')
prospects_df = load_json_to_df('bases/prospects.json')
applicants_df = load_json_to_df('bases/applicants.json')

# =======================
# 2. Pré-processamento inicial
# =======================

# Expandir as prospecções
expanded_rows = []
for job_id, job_data in prospects_df.iterrows():
    for prospect in job_data['prospects']:
        expanded_rows.append({
            'codigo_vaga': job_id,
            'codigo_candidato': prospect['codigo'],
            'situacao': prospect['situacao_candidado']
        })

prospects_flat = pd.DataFrame(expanded_rows)

# Filtrar contratados vs não
prospects_flat['contratado'] = prospects_flat['situacao'].apply(
    lambda x: 1 if 'contratado' in x.lower() else 0)

# Juntar com dados do candidato
applicants_df['codigo_profissional'] = applicants_df.index
applicants_flat = applicants_df.apply(lambda row: {
    'codigo_candidato': row['infos_basicas']['codigo_profissional'],
    'nivel_profissional': row['informacoes_profissionais']['nivel_profissional'],
    'nivel_academico': row['formacao_e_idiomas']['nivel_academico'],
    'nivel_ingles': row['formacao_e_idiomas']['nivel_ingles'],
    'nivel_espanhol': row['formacao_e_idiomas']['nivel_espanhol']
}, axis=1).tolist()
applicants_flat = pd.DataFrame(applicants_flat)

# Merge final
df = prospects_flat.merge(applicants_flat, on='codigo_candidato', how='left')

# Remover nulos (ou preencher com 'Desconhecido')
df.fillna('Desconhecido', inplace=True)

# =======================
# 3. Pipeline de Treinamento
# =======================

# Features e target
X = df[['nivel_profissional', 'nivel_academico', 'nivel_ingles', 'nivel_espanhol']]
y = df['contratado']

# Pré-processador: one-hot encoding
categorical_cols = X.columns.tolist()
preprocessor = ColumnTransformer(transformers=[
    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
])

# Modelo
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(max_iter=1000))
])

# Treinamento
X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.2, random_state=42)
model.fit(X_train, y_train)

# Avaliação
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

# =======================
# 4. Salvando o modelo
# =======================
# joblib.dump(model, 'modelo_contratacao.pkl')
filename = 'modelo_contratacao.pkl'
pickle.dump(model, open(filename, 'wb'))
